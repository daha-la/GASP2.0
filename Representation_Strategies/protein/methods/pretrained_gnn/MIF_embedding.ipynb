{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_models.pretrained import load_model_and_alphabet\n",
    "from sequence_models.pdb_utils import parse_PDB, process_coords\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import AlignIO\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "current_dir = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '../../../../'))\n",
    "sys.path.append(project_root)\n",
    "from src.helper_functions import alignment_to_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhard\\anaconda3\\envs\\GASP2.0\\Lib\\site-packages\\sequence_models\\pretrained.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_data = torch.load(model_name, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters\n",
    "folder_path = 'AF2_models/original/' # Folder with the PDB files to be embedded\n",
    "outname = 'mif' # Name of the output file\n",
    "align = AlignIO.read('../alignment/seqs.afa', \"fasta\") # Alignment file for generating mean aligned embeddings\n",
    "model, collater = load_model_and_alphabet('checkpoints/mif.pt') # Load the model and collater from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Align.MultipleSeqAlignment"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store raw and mean representations\n",
    "raw_rep_dict = {}\n",
    "mean_rep_dict = {}\n",
    "\n",
    "# Initialize DataFrames to store mean pooling representations, the MIF representation has 256 dimensions\n",
    "rep_mean_pooled_df = pd.DataFrame(columns=np.arange(256))\n",
    "rep_mean_pooled_Nt_df = pd.DataFrame(columns=np.arange(256))\n",
    "\n",
    "# Loop over the PDB files in the folder\n",
    "for path, dirs, files in os.walk(folder_path):\n",
    "\n",
    "    # Ensure we are in a model folder, as these folders do not contain any directories\n",
    "    if len(dirs) == 0:\n",
    "\n",
    "        # Get the protein name and the path to the PDB file\n",
    "        prot_name = os.path.basename(path)\n",
    "        pdb_path = path+'/'+prot_name+'_ranked_0.pdb'\n",
    "\n",
    "        # Parse the PDB file and process the coordinates to get the dihedral angles\n",
    "        coords, wt, _ = parse_PDB(pdb_path)\n",
    "        coords = {\n",
    "        'N': coords[:, 0],\n",
    "        'CA': coords[:, 1],\n",
    "        'C': coords[:, 2]\n",
    "            }\n",
    "        dist, omega, theta, phi = process_coords(coords)\n",
    "\n",
    "        # Create a batch with the dihedral angles and the sequence\n",
    "        batch = [[wt, torch.tensor(dist, dtype=torch.float),\n",
    "                torch.tensor(omega, dtype=torch.float),\n",
    "                torch.tensor(theta, dtype=torch.float), torch.tensor(phi, dtype=torch.float)]]\n",
    "        \n",
    "        # Get the representation of the protein\n",
    "        src, nodes, edges, connections, edge_mask = collater(batch)\n",
    "        rep = model(src, nodes, edges, connections, edge_mask)\n",
    "\n",
    "        # Store the raw and mean representations\n",
    "        raw_rep_dict[prot_name] = rep[0].detach().numpy()\n",
    "        mean_rep_dict[prot_name] = rep[0].detach().numpy().mean(axis=1)\n",
    "\n",
    "        # Store the mean pooling representations for the full sequence and the N-terminal half\n",
    "        rep_mean_pooled_df.loc[prot_name] = rep[0].detach().numpy().mean(axis=0)\n",
    "        rep_mean_pooled_Nt_df.loc[prot_name] = rep[0].detach().numpy()[:int(len(rep[0])/2)].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the mean aligned embeddings\n",
    "rep_mean_aligned_df,rep_mean_aligned_Nt_df = alignment_to_embedding(align, mean_rep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the index of the dataframes to ensure compatibility with the evaluation scripts\n",
    "rep_mean_aligned_df.index.names = ['enzyme']\n",
    "rep_mean_pooled_df.index.names = ['enzyme']\n",
    "rep_mean_aligned_Nt_df.index.names = ['enzyme']\n",
    "rep_mean_pooled_Nt_df.index.names = ['enzyme']\n",
    "\n",
    "# Save the embeddings to a TSV file, using the output name defined above\n",
    "rep_mean_aligned_df.to_csv(f'../../encodings/{outname}_align.tsv',sep='\\t')\n",
    "rep_mean_pooled_df.to_csv(f'../../encodings/{outname}_pool.tsv',sep='\\t')\n",
    "rep_mean_aligned_Nt_df.to_csv(f'../../encodings/{outname}_align_Nt.tsv',sep='\\t')\n",
    "rep_mean_pooled_Nt_df.to_csv(f'../../encodings/{outname}_pool_Nt.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GASP2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
